{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4) ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y69_ALGxFWxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reference: \n",
        "# https://github.com/priya-dwivedi/Deep-Learning/blob/master/resnet_keras/Residual_Networks_yourself.ipynb\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvoHspjeH7nQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "#df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVvO45_sIJOm",
        "colab_type": "code",
        "outputId": "74105d49-45d8-451b-d934-fc706a7e7ad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = df['Label']\n",
        "X = df.drop(columns=['Id', 'Label'])\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxMuuxdWL-62",
        "colab_type": "code",
        "outputId": "d7c3ef9b-1ef7-48cc-d157-a6e5c907772e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train = x_train.values.reshape((-1, 28, 28, 1))\n",
        "x_test = x_test.values.reshape((-1, 28, 28, 1))\n",
        "print(x_train.shape, x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54000, 28, 28, 1) (6000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvPrkWqzMIQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.astype(\"float32\")/255\n",
        "x_test = x_test.astype(\"float32\")/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPQQeFheS9e0",
        "colab_type": "code",
        "outputId": "48978b5b-2bea-48a7-d3a5-b38907b6e4b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO6RN943NUlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deep Learning Libraries\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Lambda, Input, ZeroPadding2D\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ReduceLROnPlateau, LearningRateScheduler\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.applications import VGG19\n",
        "from keras.layers import Add, Activation, GlobalAveragePooling2D\n",
        "import keras\n",
        "\n",
        "\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pylab as pylab\n",
        "import seaborn as sns\n",
        "import missingno as msno"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfI9ugAMz8aP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train = to_categorical(y_train, num_classes=5)\n",
        "y_test = to_categorical(y_test, num_classes=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xUjXsq2ENxWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "keras.backend.clear_session()\n",
        "#model.add(BatchNormalization())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cl-M3rhP9vsZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_block(X, f, filters, stage, block):\n",
        "    \"\"\"\n",
        "    Implementation of the identity block as defined in Figure 3\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value. You'll need this later to add back to the main path. \n",
        "    X_shortcut = X\n",
        "    \n",
        "    # First component of main path\n",
        "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    \n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0dY8hCv9583",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convolutional_block(X, f, filters, stage, block, s = 2):\n",
        "    \"\"\"\n",
        "    Implementation of the convolutional block as defined in Figure 4\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
        "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
        "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
        "    stage -- integer, used to name the layers, depending on their position in the network\n",
        "    block -- string/character, used to name the layers, depending on their position in the network\n",
        "    s -- Integer, specifying the stride to be used\n",
        "    \n",
        "    Returns:\n",
        "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
        "    \"\"\"\n",
        "    \n",
        "    # defining name basis\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # Retrieve Filters\n",
        "    F1, F2, F3 = filters\n",
        "    \n",
        "    # Save the input value\n",
        "    X_shortcut = X\n",
        "\n",
        "\n",
        "    ##### MAIN PATH #####\n",
        "    # First component of main path \n",
        "    X = Conv2D(F1, (1, 1), strides = (s,s), name = conv_name_base + '2a', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2a')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # Second component of main path (≈3 lines)\n",
        "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same', name = conv_name_base + '2b', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2b')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "\n",
        "    # Third component of main path (≈2 lines)\n",
        "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid', name = conv_name_base + '2c', kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis = 3, name = bn_name_base + '2c')(X)\n",
        "\n",
        "\n",
        "    ##### SHORTCUT PATH #### (≈2 lines)\n",
        "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (s,s), padding = 'valid', name = conv_name_base + '1',\n",
        "                        kernel_initializer = glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis = 3, name = bn_name_base + '1')(X_shortcut)\n",
        "\n",
        "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
        "    X = Add()([X, X_shortcut])\n",
        "    X = Activation('relu')(X)\n",
        "    \n",
        "    \n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T9vlEnw9-fG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def ResNet50(input_shape=(28, 28, 1), classes=1):\n",
        "    \"\"\"\n",
        "    Implementation of the popular ResNet50 the following architecture:\n",
        "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
        "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> TOPLAYER\n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the input as a tensor with shape input_shape\n",
        "    X_input = Input(input_shape)\n",
        "\n",
        "    # Zero-Padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # Stage 1\n",
        "    X = Conv2D(64, (7, 7), strides=(2, 2), name='conv1', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='bn_conv1')(X)\n",
        "    X = Activation('relu')(X)\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # Stage 2\n",
        "    X = convolutional_block(X, f=3, filters=[32, 32, 128], stage=2, block='a', s=1)\n",
        "    X = identity_block(X, 3, [32, 32, 128], stage=2, block='b')\n",
        "    # X = identity_block(X, 3, [64, 64, 128], stage=2, block='c')\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    # Stage 3 (≈4 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], stage = 3, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='b')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='c')\n",
        "    X = identity_block(X, 3, [128, 128, 512], stage=3, block='d')\n",
        "\n",
        "    # Stage 4 (≈6 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], stage = 4, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    X = identity_block(X, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # Stage 5 (≈3 lines)\n",
        "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], stage = 5, block='a', s = 2)\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    X = identity_block(X, 3, [512, 512, 2048], stage=5, block='c')\n",
        "\n",
        "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"'''\n",
        "    X = AveragePooling2D((2,2), name=\"avg_pool\", padding=\"same\")(X)\n",
        "    # X = GlobalAveragePooling2D()(X)\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # output layer\n",
        "    X = Flatten()(X)\n",
        "\n",
        "    X = Dense(256, activation='relu')(X)\n",
        "    X = Dropout(0.25)(X)\n",
        "    X = Dense(32, activation='relu')(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
        "    \n",
        "    \n",
        "    # Create model\n",
        "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AqI0rQ2wKvJf",
        "outputId": "897d5bda-d098-41a5-93f8-1a17b55754c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from keras.initializers import glorot_uniform\n",
        "from keras.layers import AveragePooling2D\n",
        "keras.backend.clear_session()\n",
        "\n",
        "model = ResNet50(input_shape = (28, 28, 1), classes = 5)\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer = Adam(), metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4074: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Model: \"ResNet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, 34, 34, 1)    0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1 (Conv2D)                  (None, 14, 14, 64)   3200        zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "bn_conv1 (BatchNormalization)   (None, 14, 14, 64)   256         conv1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 14, 14, 64)   0           bn_conv1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 6, 6, 64)     0           activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2a (Conv2D)         (None, 6, 6, 32)     2080        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2a (BatchNormalizati (None, 6, 6, 32)     128         res2a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 6, 6, 32)     0           bn2a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2b (Conv2D)         (None, 6, 6, 32)     9248        activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2b (BatchNormalizati (None, 6, 6, 32)     128         res2a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 6, 6, 32)     0           bn2a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch2c (Conv2D)         (None, 6, 6, 128)    4224        activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res2a_branch1 (Conv2D)          (None, 6, 6, 128)    8320        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch2c (BatchNormalizati (None, 6, 6, 128)    512         res2a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn2a_branch1 (BatchNormalizatio (None, 6, 6, 128)    512         res2a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 6, 6, 128)    0           bn2a_branch2c[0][0]              \n",
            "                                                                 bn2a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 6, 6, 128)    0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2a (Conv2D)         (None, 6, 6, 32)     4128        activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2a (BatchNormalizati (None, 6, 6, 32)     128         res2b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 6, 6, 32)     0           bn2b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2b (Conv2D)         (None, 6, 6, 32)     9248        activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2b (BatchNormalizati (None, 6, 6, 32)     128         res2b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 6, 6, 32)     0           bn2b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res2b_branch2c (Conv2D)         (None, 6, 6, 128)    4224        activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn2b_branch2c (BatchNormalizati (None, 6, 6, 128)    512         res2b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 6, 6, 128)    0           bn2b_branch2c[0][0]              \n",
            "                                                                 activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 6, 6, 128)    0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2a (Conv2D)         (None, 3, 3, 128)    16512       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 3, 3, 128)    0           bn3a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 3, 3, 128)    0           bn3a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "res3a_branch1 (Conv2D)          (None, 3, 3, 512)    66048       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn3a_branch1 (BatchNormalizatio (None, 3, 3, 512)    2048        res3a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 3, 3, 512)    0           bn3a_branch2c[0][0]              \n",
            "                                                                 bn3a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 3, 3, 512)    0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 3, 3, 128)    0           bn3b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 3, 3, 128)    0           bn3b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3b_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3b_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 3, 3, 512)    0           bn3b_branch2c[0][0]              \n",
            "                                                                 activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 3, 3, 512)    0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 3, 3, 128)    0           bn3c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 3, 3, 128)    0           bn3c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3c_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3c_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 3, 3, 512)    0           bn3c_branch2c[0][0]              \n",
            "                                                                 activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 3, 3, 512)    0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2a (Conv2D)         (None, 3, 3, 128)    65664       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2a (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 3, 3, 128)    0           bn3d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2b (Conv2D)         (None, 3, 3, 128)    147584      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2b (BatchNormalizati (None, 3, 3, 128)    512         res3d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 3, 3, 128)    0           bn3d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res3d_branch2c (Conv2D)         (None, 3, 3, 512)    66048       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn3d_branch2c (BatchNormalizati (None, 3, 3, 512)    2048        res3d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 3, 3, 512)    0           bn3d_branch2c[0][0]              \n",
            "                                                                 activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 3, 3, 512)    0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2a (Conv2D)         (None, 2, 2, 256)    131328      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 2, 2, 256)    0           bn4a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4a_branch1 (Conv2D)          (None, 2, 2, 1024)   525312      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn4a_branch1 (BatchNormalizatio (None, 2, 2, 1024)   4096        res4a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 2, 2, 1024)   0           bn4a_branch2c[0][0]              \n",
            "                                                                 bn4a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 2, 2, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 2, 2, 256)    0           bn4b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4b_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4b_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 2, 2, 1024)   0           bn4b_branch2c[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 2, 2, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 2, 2, 256)    0           bn4c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4c_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4c_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 2, 2, 1024)   0           bn4c_branch2c[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 2, 2, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4d_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 2, 2, 256)    0           bn4d_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4d_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4d_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4d_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 2, 2, 1024)   0           bn4d_branch2c[0][0]              \n",
            "                                                                 activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 2, 2, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4e_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 2, 2, 256)    0           bn4e_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4e_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4e_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4e_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 2, 2, 1024)   0           bn4e_branch2c[0][0]              \n",
            "                                                                 activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 2, 2, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2a (Conv2D)         (None, 2, 2, 256)    262400      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2a (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2b (Conv2D)         (None, 2, 2, 256)    590080      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2b (BatchNormalizati (None, 2, 2, 256)    1024        res4f_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 2, 2, 256)    0           bn4f_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res4f_branch2c (Conv2D)         (None, 2, 2, 1024)   263168      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn4f_branch2c (BatchNormalizati (None, 2, 2, 1024)   4096        res4f_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 2, 2, 1024)   0           bn4f_branch2c[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 2, 2, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2a (Conv2D)         (None, 1, 1, 512)    524800      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5a_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 1, 1, 512)    0           bn5a_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5a_branch1 (Conv2D)          (None, 1, 1, 2048)   2099200     activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5a_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "bn5a_branch1 (BatchNormalizatio (None, 1, 1, 2048)   8192        res5a_branch1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 1, 1, 2048)   0           bn5a_branch2c[0][0]              \n",
            "                                                                 bn5a_branch1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 1, 1, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5b_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 1, 1, 512)    0           bn5b_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5b_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5b_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5b_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 1, 1, 2048)   0           bn5b_branch2c[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 1, 1, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2a (Conv2D)         (None, 1, 1, 512)    1049088     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2a (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2a[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2a[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2b (Conv2D)         (None, 1, 1, 512)    2359808     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2b (BatchNormalizati (None, 1, 1, 512)    2048        res5c_branch2b[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 1, 1, 512)    0           bn5c_branch2b[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "res5c_branch2c (Conv2D)         (None, 1, 1, 2048)   1050624     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "bn5c_branch2c (BatchNormalizati (None, 1, 1, 2048)   8192        res5c_branch2c[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 1, 1, 2048)   0           bn5c_branch2c[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 1, 1, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (AveragePooling2D)     (None, 1, 1, 2048)   0           activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 2048)         0           avg_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 256)          524544      flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           8224        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "fc5 (Dense)                     (None, 5)            165         dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,855,941\n",
            "Trainable params: 23,804,613\n",
            "Non-trainable params: 51,328\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3QQICcM-Km",
        "colab_type": "code",
        "outputId": "1c42a6f4-38dc-4315-dd74-a05af00e70fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train,\n",
        "          batch_size=1024,\n",
        "          epochs=300,\n",
        "          shuffle = True,\n",
        "          validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Train on 54000 samples, validate on 6000 samples\n",
            "Epoch 1/300\n",
            "54000/54000 [==============================] - 67s 1ms/step - loss: 0.9423 - accuracy: 0.6656 - val_loss: 1.6348 - val_accuracy: 0.2050\n",
            "Epoch 2/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.4528 - accuracy: 0.8255 - val_loss: 1.7014 - val_accuracy: 0.2050\n",
            "Epoch 3/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.4058 - accuracy: 0.8454 - val_loss: 1.7209 - val_accuracy: 0.2237\n",
            "Epoch 4/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.3517 - accuracy: 0.8646 - val_loss: 1.7342 - val_accuracy: 0.2162\n",
            "Epoch 5/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.3160 - accuracy: 0.8782 - val_loss: 1.6987 - val_accuracy: 0.3220\n",
            "Epoch 6/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.2679 - accuracy: 0.8976 - val_loss: 1.4753 - val_accuracy: 0.4345\n",
            "Epoch 7/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.2493 - accuracy: 0.9023 - val_loss: 1.4367 - val_accuracy: 0.4598\n",
            "Epoch 8/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.2252 - accuracy: 0.9120 - val_loss: 1.1978 - val_accuracy: 0.5718\n",
            "Epoch 9/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.2184 - accuracy: 0.9141 - val_loss: 0.8763 - val_accuracy: 0.6922\n",
            "Epoch 10/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.1966 - accuracy: 0.9239 - val_loss: 0.5394 - val_accuracy: 0.8063\n",
            "Epoch 11/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.1748 - accuracy: 0.9331 - val_loss: 0.5812 - val_accuracy: 0.8203\n",
            "Epoch 12/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.1814 - accuracy: 0.9296 - val_loss: 0.5128 - val_accuracy: 0.8327\n",
            "Epoch 13/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.1619 - accuracy: 0.9367 - val_loss: 0.5022 - val_accuracy: 0.8392\n",
            "Epoch 14/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.1566 - accuracy: 0.9401 - val_loss: 0.6696 - val_accuracy: 0.7917\n",
            "Epoch 15/300\n",
            "54000/54000 [==============================] - 36s 675us/step - loss: 0.1366 - accuracy: 0.9465 - val_loss: 0.5557 - val_accuracy: 0.8372\n",
            "Epoch 16/300\n",
            "54000/54000 [==============================] - 36s 675us/step - loss: 0.1695 - accuracy: 0.9347 - val_loss: 0.4592 - val_accuracy: 0.8595\n",
            "Epoch 17/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1346 - accuracy: 0.9488 - val_loss: 0.5201 - val_accuracy: 0.8483\n",
            "Epoch 18/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1244 - accuracy: 0.9534 - val_loss: 0.5513 - val_accuracy: 0.8362\n",
            "Epoch 19/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1316 - accuracy: 0.9499 - val_loss: 0.4913 - val_accuracy: 0.8623\n",
            "Epoch 20/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.1154 - accuracy: 0.9569 - val_loss: 0.7518 - val_accuracy: 0.8220\n",
            "Epoch 21/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1111 - accuracy: 0.9582 - val_loss: 0.8370 - val_accuracy: 0.7907\n",
            "Epoch 22/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1009 - accuracy: 0.9605 - val_loss: 0.5834 - val_accuracy: 0.8413\n",
            "Epoch 23/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0918 - accuracy: 0.9656 - val_loss: 0.4917 - val_accuracy: 0.8560\n",
            "Epoch 24/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0900 - accuracy: 0.9656 - val_loss: 0.6493 - val_accuracy: 0.8352\n",
            "Epoch 25/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0796 - accuracy: 0.9700 - val_loss: 0.6584 - val_accuracy: 0.8303\n",
            "Epoch 26/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0798 - accuracy: 0.9702 - val_loss: 0.5605 - val_accuracy: 0.8555\n",
            "Epoch 27/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0748 - accuracy: 0.9722 - val_loss: 0.6851 - val_accuracy: 0.8302\n",
            "Epoch 28/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0764 - accuracy: 0.9725 - val_loss: 0.5645 - val_accuracy: 0.8597\n",
            "Epoch 29/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0847 - accuracy: 0.9697 - val_loss: 0.5062 - val_accuracy: 0.8668\n",
            "Epoch 30/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0679 - accuracy: 0.9744 - val_loss: 0.6961 - val_accuracy: 0.8372\n",
            "Epoch 31/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0722 - accuracy: 0.9728 - val_loss: 0.6079 - val_accuracy: 0.8570\n",
            "Epoch 32/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0744 - accuracy: 0.9722 - val_loss: 0.5526 - val_accuracy: 0.8655\n",
            "Epoch 33/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0531 - accuracy: 0.9804 - val_loss: 0.5556 - val_accuracy: 0.8675\n",
            "Epoch 34/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.6668 - val_accuracy: 0.8367\n",
            "Epoch 35/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0626 - accuracy: 0.9771 - val_loss: 0.6339 - val_accuracy: 0.8328\n",
            "Epoch 36/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0700 - accuracy: 0.9752 - val_loss: 0.6462 - val_accuracy: 0.8517\n",
            "Epoch 37/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0623 - accuracy: 0.9769 - val_loss: 0.6280 - val_accuracy: 0.8467\n",
            "Epoch 38/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0573 - accuracy: 0.9796 - val_loss: 0.6382 - val_accuracy: 0.8448\n",
            "Epoch 39/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0543 - accuracy: 0.9796 - val_loss: 0.7672 - val_accuracy: 0.8178\n",
            "Epoch 40/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0614 - accuracy: 0.9767 - val_loss: 0.6096 - val_accuracy: 0.8630\n",
            "Epoch 41/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0505 - accuracy: 0.9806 - val_loss: 0.8970 - val_accuracy: 0.8367\n",
            "Epoch 42/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0529 - accuracy: 0.9811 - val_loss: 0.6115 - val_accuracy: 0.8587\n",
            "Epoch 43/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0472 - accuracy: 0.9830 - val_loss: 0.6452 - val_accuracy: 0.8547\n",
            "Epoch 44/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0463 - accuracy: 0.9828 - val_loss: 0.5694 - val_accuracy: 0.8677\n",
            "Epoch 45/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0419 - accuracy: 0.9854 - val_loss: 0.6138 - val_accuracy: 0.8732\n",
            "Epoch 46/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0408 - accuracy: 0.9848 - val_loss: 0.7434 - val_accuracy: 0.8520\n",
            "Epoch 47/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0487 - accuracy: 0.9829 - val_loss: 0.7044 - val_accuracy: 0.8535\n",
            "Epoch 48/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0442 - accuracy: 0.9841 - val_loss: 0.7062 - val_accuracy: 0.8473\n",
            "Epoch 49/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0400 - accuracy: 0.9857 - val_loss: 0.6717 - val_accuracy: 0.8493\n",
            "Epoch 50/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.5649 - val_accuracy: 0.8690\n",
            "Epoch 51/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0389 - accuracy: 0.9858 - val_loss: 0.6468 - val_accuracy: 0.8673\n",
            "Epoch 52/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0391 - accuracy: 0.9860 - val_loss: 0.6730 - val_accuracy: 0.8670\n",
            "Epoch 53/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0390 - accuracy: 0.9861 - val_loss: 0.6298 - val_accuracy: 0.8530\n",
            "Epoch 54/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0385 - accuracy: 0.9868 - val_loss: 0.5898 - val_accuracy: 0.8608\n",
            "Epoch 55/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0462 - accuracy: 0.9839 - val_loss: 0.5832 - val_accuracy: 0.8680\n",
            "Epoch 56/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0372 - accuracy: 0.9869 - val_loss: 0.6330 - val_accuracy: 0.8688\n",
            "Epoch 57/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0374 - accuracy: 0.9869 - val_loss: 0.8216 - val_accuracy: 0.8405\n",
            "Epoch 58/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0308 - accuracy: 0.9889 - val_loss: 0.7518 - val_accuracy: 0.8555\n",
            "Epoch 59/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0429 - accuracy: 0.9848 - val_loss: 0.6951 - val_accuracy: 0.8542\n",
            "Epoch 60/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0350 - accuracy: 0.9876 - val_loss: 0.6219 - val_accuracy: 0.8645\n",
            "Epoch 61/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0337 - accuracy: 0.9885 - val_loss: 0.6149 - val_accuracy: 0.8585\n",
            "Epoch 62/300\n",
            "54000/54000 [==============================] - 37s 683us/step - loss: 0.0289 - accuracy: 0.9894 - val_loss: 0.8590 - val_accuracy: 0.8315\n",
            "Epoch 63/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0324 - accuracy: 0.9887 - val_loss: 0.6617 - val_accuracy: 0.8602\n",
            "Epoch 64/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0368 - accuracy: 0.9865 - val_loss: 0.7968 - val_accuracy: 0.8435\n",
            "Epoch 65/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0292 - accuracy: 0.9899 - val_loss: 0.7215 - val_accuracy: 0.8578\n",
            "Epoch 66/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0365 - accuracy: 0.9868 - val_loss: 0.7925 - val_accuracy: 0.8418\n",
            "Epoch 67/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0276 - accuracy: 0.9900 - val_loss: 0.7198 - val_accuracy: 0.8655\n",
            "Epoch 68/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0269 - accuracy: 0.9903 - val_loss: 0.8693 - val_accuracy: 0.8352\n",
            "Epoch 69/300\n",
            "54000/54000 [==============================] - 37s 676us/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.6929 - val_accuracy: 0.8637\n",
            "Epoch 70/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0325 - accuracy: 0.9885 - val_loss: 0.6657 - val_accuracy: 0.8650\n",
            "Epoch 71/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0310 - accuracy: 0.9891 - val_loss: 0.8713 - val_accuracy: 0.8298\n",
            "Epoch 72/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.8482 - val_accuracy: 0.8465\n",
            "Epoch 73/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0298 - accuracy: 0.9895 - val_loss: 0.8438 - val_accuracy: 0.8605\n",
            "Epoch 74/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0370 - accuracy: 0.9876 - val_loss: 9.4550 - val_accuracy: 0.7677\n",
            "Epoch 75/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0533 - accuracy: 0.9817 - val_loss: 8.3805 - val_accuracy: 0.7843\n",
            "Epoch 76/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 1.4638 - val_accuracy: 0.8593\n",
            "Epoch 77/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0312 - accuracy: 0.9895 - val_loss: 0.8535 - val_accuracy: 0.8473\n",
            "Epoch 78/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0282 - accuracy: 0.9907 - val_loss: 0.7689 - val_accuracy: 0.8518\n",
            "Epoch 79/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 0.6476 - val_accuracy: 0.8632\n",
            "Epoch 80/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0278 - accuracy: 0.9905 - val_loss: 0.6892 - val_accuracy: 0.8732\n",
            "Epoch 81/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.6110 - val_accuracy: 0.8655\n",
            "Epoch 82/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0243 - accuracy: 0.9920 - val_loss: 0.6840 - val_accuracy: 0.8677\n",
            "Epoch 83/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0294 - accuracy: 0.9902 - val_loss: 0.8687 - val_accuracy: 0.8398\n",
            "Epoch 84/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.7850 - val_accuracy: 0.8693\n",
            "Epoch 85/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0255 - accuracy: 0.9910 - val_loss: 0.9078 - val_accuracy: 0.8333\n",
            "Epoch 86/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0260 - accuracy: 0.9914 - val_loss: 0.6374 - val_accuracy: 0.8623\n",
            "Epoch 87/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0284 - accuracy: 0.9898 - val_loss: 0.6886 - val_accuracy: 0.8658\n",
            "Epoch 88/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0257 - accuracy: 0.9914 - val_loss: 0.6502 - val_accuracy: 0.8690\n",
            "Epoch 89/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0286 - accuracy: 0.9899 - val_loss: 0.7883 - val_accuracy: 0.8582\n",
            "Epoch 90/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0268 - accuracy: 0.9908 - val_loss: 0.8148 - val_accuracy: 0.8430\n",
            "Epoch 91/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0277 - accuracy: 0.9907 - val_loss: 0.6487 - val_accuracy: 0.8723\n",
            "Epoch 92/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0187 - accuracy: 0.9933 - val_loss: 0.7068 - val_accuracy: 0.8637\n",
            "Epoch 93/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0212 - accuracy: 0.9923 - val_loss: 0.6842 - val_accuracy: 0.8642\n",
            "Epoch 94/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.6750 - val_accuracy: 0.8677\n",
            "Epoch 95/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0207 - accuracy: 0.9927 - val_loss: 0.8513 - val_accuracy: 0.8430\n",
            "Epoch 96/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0291 - accuracy: 0.9905 - val_loss: 0.6331 - val_accuracy: 0.8657\n",
            "Epoch 97/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0237 - accuracy: 0.9919 - val_loss: 0.7195 - val_accuracy: 0.8685\n",
            "Epoch 98/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.6462 - val_accuracy: 0.8683\n",
            "Epoch 99/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0240 - accuracy: 0.9919 - val_loss: 0.8366 - val_accuracy: 0.8607\n",
            "Epoch 100/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0254 - accuracy: 0.9916 - val_loss: 0.9366 - val_accuracy: 0.8442\n",
            "Epoch 101/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0252 - accuracy: 0.9912 - val_loss: 0.8453 - val_accuracy: 0.8573\n",
            "Epoch 102/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0184 - accuracy: 0.9936 - val_loss: 0.7250 - val_accuracy: 0.8655\n",
            "Epoch 103/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.7378 - val_accuracy: 0.8607\n",
            "Epoch 104/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0244 - accuracy: 0.9918 - val_loss: 0.6792 - val_accuracy: 0.8725\n",
            "Epoch 105/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0257 - accuracy: 0.9912 - val_loss: 0.7484 - val_accuracy: 0.8678\n",
            "Epoch 106/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0218 - accuracy: 0.9928 - val_loss: 0.7599 - val_accuracy: 0.8645\n",
            "Epoch 107/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0265 - accuracy: 0.9910 - val_loss: 0.8792 - val_accuracy: 0.8582\n",
            "Epoch 108/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0221 - accuracy: 0.9927 - val_loss: 0.8892 - val_accuracy: 0.8500\n",
            "Epoch 109/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.8329 - val_accuracy: 0.8488\n",
            "Epoch 110/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0188 - accuracy: 0.9934 - val_loss: 0.7186 - val_accuracy: 0.8608\n",
            "Epoch 111/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0239 - accuracy: 0.9917 - val_loss: 0.7990 - val_accuracy: 0.8675\n",
            "Epoch 112/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0323 - accuracy: 0.9889 - val_loss: 0.8789 - val_accuracy: 0.8402\n",
            "Epoch 113/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0194 - accuracy: 0.9928 - val_loss: 0.7431 - val_accuracy: 0.8673\n",
            "Epoch 114/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0222 - accuracy: 0.9926 - val_loss: 0.8811 - val_accuracy: 0.8512\n",
            "Epoch 115/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0202 - accuracy: 0.9934 - val_loss: 0.7189 - val_accuracy: 0.8630\n",
            "Epoch 116/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.7391 - val_accuracy: 0.8637\n",
            "Epoch 117/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.7280 - val_accuracy: 0.8635\n",
            "Epoch 118/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0197 - accuracy: 0.9935 - val_loss: 0.7538 - val_accuracy: 0.8642\n",
            "Epoch 119/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0209 - accuracy: 0.9931 - val_loss: 0.7386 - val_accuracy: 0.8670\n",
            "Epoch 120/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0181 - accuracy: 0.9938 - val_loss: 0.7431 - val_accuracy: 0.8615\n",
            "Epoch 121/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0207 - accuracy: 0.9932 - val_loss: 0.6664 - val_accuracy: 0.8692\n",
            "Epoch 122/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0164 - accuracy: 0.9946 - val_loss: 0.9661 - val_accuracy: 0.8340\n",
            "Epoch 123/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0210 - accuracy: 0.9933 - val_loss: 0.8384 - val_accuracy: 0.8527\n",
            "Epoch 124/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0237 - accuracy: 0.9914 - val_loss: 0.6563 - val_accuracy: 0.8743\n",
            "Epoch 125/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0171 - accuracy: 0.9943 - val_loss: 0.7994 - val_accuracy: 0.8677\n",
            "Epoch 126/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0210 - accuracy: 0.9932 - val_loss: 0.7845 - val_accuracy: 0.8642\n",
            "Epoch 127/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0176 - accuracy: 0.9941 - val_loss: 0.7035 - val_accuracy: 0.8750\n",
            "Epoch 128/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0166 - accuracy: 0.9946 - val_loss: 0.8161 - val_accuracy: 0.8595\n",
            "Epoch 129/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0202 - accuracy: 0.9932 - val_loss: 0.7292 - val_accuracy: 0.8677\n",
            "Epoch 130/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0147 - accuracy: 0.9946 - val_loss: 0.7806 - val_accuracy: 0.8635\n",
            "Epoch 131/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0151 - accuracy: 0.9949 - val_loss: 0.7604 - val_accuracy: 0.8710\n",
            "Epoch 132/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0182 - accuracy: 0.9940 - val_loss: 0.8594 - val_accuracy: 0.8565\n",
            "Epoch 133/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0224 - accuracy: 0.9926 - val_loss: 0.6346 - val_accuracy: 0.8692\n",
            "Epoch 134/300\n",
            "54000/54000 [==============================] - 36s 675us/step - loss: 0.0198 - accuracy: 0.9933 - val_loss: 0.6885 - val_accuracy: 0.8738\n",
            "Epoch 135/300\n",
            "54000/54000 [==============================] - 36s 676us/step - loss: 0.0230 - accuracy: 0.9923 - val_loss: 0.7781 - val_accuracy: 0.8528\n",
            "Epoch 136/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0205 - accuracy: 0.9935 - val_loss: 0.6756 - val_accuracy: 0.8723\n",
            "Epoch 137/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.7107 - val_accuracy: 0.8602\n",
            "Epoch 138/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.1657 - accuracy: 0.9741 - val_loss: 47875.0387 - val_accuracy: 0.2050\n",
            "Epoch 139/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.5006 - accuracy: 0.8115 - val_loss: 500.5450 - val_accuracy: 0.2108\n",
            "Epoch 140/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.3154 - accuracy: 0.8766 - val_loss: 11.0418 - val_accuracy: 0.7177\n",
            "Epoch 141/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.2417 - accuracy: 0.9065 - val_loss: 0.4359 - val_accuracy: 0.8567\n",
            "Epoch 142/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.2063 - accuracy: 0.9195 - val_loss: 0.3724 - val_accuracy: 0.8705\n",
            "Epoch 143/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.1616 - accuracy: 0.9383 - val_loss: 0.3492 - val_accuracy: 0.8788\n",
            "Epoch 144/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.1364 - accuracy: 0.9480 - val_loss: 0.3865 - val_accuracy: 0.8737\n",
            "Epoch 145/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.1145 - accuracy: 0.9564 - val_loss: 0.4805 - val_accuracy: 0.8648\n",
            "Epoch 146/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0915 - accuracy: 0.9659 - val_loss: 0.4522 - val_accuracy: 0.8742\n",
            "Epoch 147/300\n",
            "54000/54000 [==============================] - 36s 675us/step - loss: 0.0848 - accuracy: 0.9691 - val_loss: 0.4239 - val_accuracy: 0.8763\n",
            "Epoch 148/300\n",
            "54000/54000 [==============================] - 36s 672us/step - loss: 0.0779 - accuracy: 0.9709 - val_loss: 0.5015 - val_accuracy: 0.8660\n",
            "Epoch 149/300\n",
            "54000/54000 [==============================] - 37s 676us/step - loss: 0.0613 - accuracy: 0.9773 - val_loss: 0.5057 - val_accuracy: 0.8735\n",
            "Epoch 150/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0539 - accuracy: 0.9793 - val_loss: 0.5091 - val_accuracy: 0.8788\n",
            "Epoch 151/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0469 - accuracy: 0.9827 - val_loss: 0.5875 - val_accuracy: 0.8758\n",
            "Epoch 152/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0527 - accuracy: 0.9809 - val_loss: 0.5447 - val_accuracy: 0.8730\n",
            "Epoch 153/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0470 - accuracy: 0.9821 - val_loss: 0.6021 - val_accuracy: 0.8727\n",
            "Epoch 154/300\n",
            "54000/54000 [==============================] - 37s 680us/step - loss: 0.0434 - accuracy: 0.9847 - val_loss: 0.6028 - val_accuracy: 0.8677\n",
            "Epoch 155/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0489 - accuracy: 0.9816 - val_loss: 0.6678 - val_accuracy: 0.8568\n",
            "Epoch 156/300\n",
            "54000/54000 [==============================] - 37s 684us/step - loss: 0.0402 - accuracy: 0.9850 - val_loss: 0.7236 - val_accuracy: 0.8627\n",
            "Epoch 157/300\n",
            "54000/54000 [==============================] - 36s 674us/step - loss: 0.0368 - accuracy: 0.9865 - val_loss: 0.6272 - val_accuracy: 0.8687\n",
            "Epoch 158/300\n",
            "54000/54000 [==============================] - 37s 682us/step - loss: 0.0350 - accuracy: 0.9873 - val_loss: 0.5706 - val_accuracy: 0.8735\n",
            "Epoch 159/300\n",
            "54000/54000 [==============================] - 36s 674us/step - loss: 0.0244 - accuracy: 0.9914 - val_loss: 0.6444 - val_accuracy: 0.8780\n",
            "Epoch 160/300\n",
            "54000/54000 [==============================] - 36s 675us/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.5766 - val_accuracy: 0.8783\n",
            "Epoch 161/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.6382 - val_accuracy: 0.8735\n",
            "Epoch 162/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0391 - accuracy: 0.9862 - val_loss: 0.7094 - val_accuracy: 0.8495\n",
            "Epoch 163/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.7288 - val_accuracy: 0.8677\n",
            "Epoch 164/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0288 - accuracy: 0.9901 - val_loss: 0.6498 - val_accuracy: 0.8760\n",
            "Epoch 165/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 0.7835 - val_accuracy: 0.8680\n",
            "Epoch 166/300\n",
            "54000/54000 [==============================] - 37s 681us/step - loss: 0.0226 - accuracy: 0.9923 - val_loss: 0.6411 - val_accuracy: 0.8808\n",
            "Epoch 167/300\n",
            "54000/54000 [==============================] - 37s 676us/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.6609 - val_accuracy: 0.8748\n",
            "Epoch 168/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 0.6079 - val_accuracy: 0.8772\n",
            "Epoch 169/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.7212 - val_accuracy: 0.8633\n",
            "Epoch 170/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0176 - accuracy: 0.9940 - val_loss: 0.6802 - val_accuracy: 0.8782\n",
            "Epoch 171/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0260 - accuracy: 0.9912 - val_loss: 0.6411 - val_accuracy: 0.8760\n",
            "Epoch 172/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0196 - accuracy: 0.9932 - val_loss: 0.6889 - val_accuracy: 0.8745\n",
            "Epoch 173/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0263 - accuracy: 0.9911 - val_loss: 0.5798 - val_accuracy: 0.8762\n",
            "Epoch 174/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0197 - accuracy: 0.9936 - val_loss: 0.7510 - val_accuracy: 0.8663\n",
            "Epoch 175/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0238 - accuracy: 0.9921 - val_loss: 0.6751 - val_accuracy: 0.8777\n",
            "Epoch 176/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0256 - accuracy: 0.9912 - val_loss: 0.6059 - val_accuracy: 0.8785\n",
            "Epoch 177/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0213 - accuracy: 0.9924 - val_loss: 0.6337 - val_accuracy: 0.8802\n",
            "Epoch 178/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.8004 - val_accuracy: 0.8615\n",
            "Epoch 179/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 0.7119 - val_accuracy: 0.8727\n",
            "Epoch 180/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0145 - accuracy: 0.9949 - val_loss: 0.7098 - val_accuracy: 0.8752\n",
            "Epoch 181/300\n",
            "54000/54000 [==============================] - 37s 677us/step - loss: 0.0227 - accuracy: 0.9925 - val_loss: 0.6501 - val_accuracy: 0.8743\n",
            "Epoch 182/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0130 - accuracy: 0.9952 - val_loss: 0.7459 - val_accuracy: 0.8742\n",
            "Epoch 183/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0212 - accuracy: 0.9932 - val_loss: 0.7681 - val_accuracy: 0.8610\n",
            "Epoch 184/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0146 - accuracy: 0.9950 - val_loss: 0.7101 - val_accuracy: 0.8752\n",
            "Epoch 185/300\n",
            "54000/54000 [==============================] - 37s 678us/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.7803 - val_accuracy: 0.8682\n",
            "Epoch 186/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.6488 - val_accuracy: 0.8638\n",
            "Epoch 187/300\n",
            "54000/54000 [==============================] - 37s 679us/step - loss: 0.0191 - accuracy: 0.9936 - val_loss: 0.6884 - val_accuracy: 0.8677\n",
            "Epoch 188/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0170 - accuracy: 0.9937 - val_loss: 0.7402 - val_accuracy: 0.8710\n",
            "Epoch 189/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0133 - accuracy: 0.9955 - val_loss: 0.7370 - val_accuracy: 0.8747\n",
            "Epoch 190/300\n",
            "54000/54000 [==============================] - 37s 684us/step - loss: 0.0206 - accuracy: 0.9925 - val_loss: 0.7111 - val_accuracy: 0.8708\n",
            "Epoch 191/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0142 - accuracy: 0.9952 - val_loss: 0.7892 - val_accuracy: 0.8723\n",
            "Epoch 192/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0180 - accuracy: 0.9947 - val_loss: 0.7684 - val_accuracy: 0.8588\n",
            "Epoch 193/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.7026 - val_accuracy: 0.8718\n",
            "Epoch 194/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.7347 - val_accuracy: 0.8663\n",
            "Epoch 195/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.7004 - val_accuracy: 0.8733\n",
            "Epoch 196/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.8977 - val_accuracy: 0.8528\n",
            "Epoch 197/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0119 - accuracy: 0.9958 - val_loss: 0.7147 - val_accuracy: 0.8755\n",
            "Epoch 198/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.1095 - accuracy: 0.9660 - val_loss: 103.8474 - val_accuracy: 0.6843\n",
            "Epoch 199/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0311 - accuracy: 0.9891 - val_loss: 10.8781 - val_accuracy: 0.7913\n",
            "Epoch 200/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0227 - accuracy: 0.9923 - val_loss: 2.0424 - val_accuracy: 0.8113\n",
            "Epoch 201/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.8520 - val_accuracy: 0.8512\n",
            "Epoch 202/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0191 - accuracy: 0.9939 - val_loss: 0.9692 - val_accuracy: 0.8392\n",
            "Epoch 203/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 0.7056 - val_accuracy: 0.8745\n",
            "Epoch 204/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.7089 - val_accuracy: 0.8745\n",
            "Epoch 205/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.7658 - val_accuracy: 0.8735\n",
            "Epoch 206/300\n",
            "54000/54000 [==============================] - 37s 684us/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.7397 - val_accuracy: 0.8687\n",
            "Epoch 207/300\n",
            "54000/54000 [==============================] - 37s 684us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.7229 - val_accuracy: 0.8713\n",
            "Epoch 208/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0129 - accuracy: 0.9956 - val_loss: 0.7606 - val_accuracy: 0.8717\n",
            "Epoch 209/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0092 - accuracy: 0.9969 - val_loss: 0.8214 - val_accuracy: 0.8695\n",
            "Epoch 210/300\n",
            "54000/54000 [==============================] - 37s 684us/step - loss: 0.0150 - accuracy: 0.9952 - val_loss: 0.6725 - val_accuracy: 0.8763\n",
            "Epoch 211/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0135 - accuracy: 0.9955 - val_loss: 0.7594 - val_accuracy: 0.8692\n",
            "Epoch 212/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.6953 - val_accuracy: 0.8767\n",
            "Epoch 213/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0171 - accuracy: 0.9942 - val_loss: 0.8246 - val_accuracy: 0.8588\n",
            "Epoch 214/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0095 - accuracy: 0.9969 - val_loss: 0.8357 - val_accuracy: 0.8695\n",
            "Epoch 215/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0156 - accuracy: 0.9942 - val_loss: 0.8230 - val_accuracy: 0.8573\n",
            "Epoch 216/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0137 - accuracy: 0.9956 - val_loss: 0.7619 - val_accuracy: 0.8708\n",
            "Epoch 217/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0154 - accuracy: 0.9950 - val_loss: 0.7286 - val_accuracy: 0.8773\n",
            "Epoch 218/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 0.7845 - val_accuracy: 0.8612\n",
            "Epoch 219/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0140 - accuracy: 0.9954 - val_loss: 0.6877 - val_accuracy: 0.8795\n",
            "Epoch 220/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0161 - accuracy: 0.9944 - val_loss: 0.7328 - val_accuracy: 0.8708\n",
            "Epoch 221/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.6951 - val_accuracy: 0.8793\n",
            "Epoch 222/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.7606 - val_accuracy: 0.8635\n",
            "Epoch 223/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.7505 - val_accuracy: 0.8750\n",
            "Epoch 224/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.7677 - val_accuracy: 0.8680\n",
            "Epoch 225/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0113 - accuracy: 0.9960 - val_loss: 0.8965 - val_accuracy: 0.8662\n",
            "Epoch 226/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0222 - accuracy: 0.9925 - val_loss: 0.7117 - val_accuracy: 0.8690\n",
            "Epoch 227/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0147 - accuracy: 0.9953 - val_loss: 0.8321 - val_accuracy: 0.8625\n",
            "Epoch 228/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0093 - accuracy: 0.9970 - val_loss: 0.7860 - val_accuracy: 0.8693\n",
            "Epoch 229/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0087 - accuracy: 0.9972 - val_loss: 0.7699 - val_accuracy: 0.8698\n",
            "Epoch 230/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0156 - accuracy: 0.9949 - val_loss: 0.7327 - val_accuracy: 0.8705\n",
            "Epoch 231/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.7324 - val_accuracy: 0.8747\n",
            "Epoch 232/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0172 - accuracy: 0.9942 - val_loss: 0.7442 - val_accuracy: 0.8790\n",
            "Epoch 233/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 0.7441 - val_accuracy: 0.8685\n",
            "Epoch 234/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0110 - accuracy: 0.9961 - val_loss: 0.8734 - val_accuracy: 0.8607\n",
            "Epoch 235/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.7469 - val_accuracy: 0.8735\n",
            "Epoch 236/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.9412 - val_accuracy: 0.8573\n",
            "Epoch 237/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0201 - accuracy: 0.9933 - val_loss: 0.7287 - val_accuracy: 0.8670\n",
            "Epoch 238/300\n",
            "54000/54000 [==============================] - 37s 689us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.6773 - val_accuracy: 0.8725\n",
            "Epoch 239/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0119 - accuracy: 0.9961 - val_loss: 0.7132 - val_accuracy: 0.8757\n",
            "Epoch 240/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 0.7051 - val_accuracy: 0.8733\n",
            "Epoch 241/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.8124 - val_accuracy: 0.8670\n",
            "Epoch 242/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0084 - accuracy: 0.9971 - val_loss: 0.8060 - val_accuracy: 0.8718\n",
            "Epoch 243/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0150 - accuracy: 0.9951 - val_loss: 0.6819 - val_accuracy: 0.8717\n",
            "Epoch 244/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0125 - accuracy: 0.9960 - val_loss: 0.7482 - val_accuracy: 0.8648\n",
            "Epoch 245/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0148 - accuracy: 0.9954 - val_loss: 0.6969 - val_accuracy: 0.8750\n",
            "Epoch 246/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0120 - accuracy: 0.9957 - val_loss: 0.8287 - val_accuracy: 0.8683\n",
            "Epoch 247/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.7591 - val_accuracy: 0.8705\n",
            "Epoch 248/300\n",
            "54000/54000 [==============================] - 37s 689us/step - loss: 0.0110 - accuracy: 0.9964 - val_loss: 0.7680 - val_accuracy: 0.8795\n",
            "Epoch 249/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0125 - accuracy: 0.9962 - val_loss: 0.7384 - val_accuracy: 0.8688\n",
            "Epoch 250/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.7616 - val_accuracy: 0.8797\n",
            "Epoch 251/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0100 - accuracy: 0.9967 - val_loss: 0.7225 - val_accuracy: 0.8740\n",
            "Epoch 252/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0098 - accuracy: 0.9968 - val_loss: 0.7660 - val_accuracy: 0.8748\n",
            "Epoch 253/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0095 - accuracy: 0.9972 - val_loss: 0.7987 - val_accuracy: 0.8645\n",
            "Epoch 254/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0110 - accuracy: 0.9968 - val_loss: 0.7695 - val_accuracy: 0.8722\n",
            "Epoch 255/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.7002 - val_accuracy: 0.8742\n",
            "Epoch 256/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0128 - accuracy: 0.9955 - val_loss: 0.7503 - val_accuracy: 0.8682\n",
            "Epoch 257/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0122 - accuracy: 0.9962 - val_loss: 0.7960 - val_accuracy: 0.8688\n",
            "Epoch 258/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0174 - accuracy: 0.9938 - val_loss: 0.7189 - val_accuracy: 0.8647\n",
            "Epoch 259/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.7607 - val_accuracy: 0.8727\n",
            "Epoch 260/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.9898 - val_accuracy: 0.8458\n",
            "Epoch 261/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0111 - accuracy: 0.9965 - val_loss: 0.7751 - val_accuracy: 0.8668\n",
            "Epoch 262/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.7827 - val_accuracy: 0.8767\n",
            "Epoch 263/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0173 - accuracy: 0.9951 - val_loss: 0.8267 - val_accuracy: 0.8755\n",
            "Epoch 264/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.8197 - val_accuracy: 0.8552\n",
            "Epoch 265/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.0850 - val_accuracy: 0.8477\n",
            "Epoch 266/300\n",
            "54000/54000 [==============================] - 37s 689us/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.8093 - val_accuracy: 0.8775\n",
            "Epoch 267/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.6967 - val_accuracy: 0.8750\n",
            "Epoch 268/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.7896 - val_accuracy: 0.8760\n",
            "Epoch 269/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0128 - accuracy: 0.9961 - val_loss: 0.7186 - val_accuracy: 0.8757\n",
            "Epoch 270/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0085 - accuracy: 0.9970 - val_loss: 0.8153 - val_accuracy: 0.8732\n",
            "Epoch 271/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0082 - accuracy: 0.9973 - val_loss: 0.7626 - val_accuracy: 0.8822\n",
            "Epoch 272/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.6804 - val_accuracy: 0.8765\n",
            "Epoch 273/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0106 - accuracy: 0.9967 - val_loss: 0.8525 - val_accuracy: 0.8612\n",
            "Epoch 274/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0118 - accuracy: 0.9961 - val_loss: 0.7593 - val_accuracy: 0.8607\n",
            "Epoch 275/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0113 - accuracy: 0.9963 - val_loss: 0.8216 - val_accuracy: 0.8608\n",
            "Epoch 276/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0082 - accuracy: 0.9971 - val_loss: 0.8082 - val_accuracy: 0.8695\n",
            "Epoch 277/300\n",
            "54000/54000 [==============================] - 37s 691us/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.7419 - val_accuracy: 0.8833\n",
            "Epoch 278/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.8339 - val_accuracy: 0.8617\n",
            "Epoch 279/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0149 - accuracy: 0.9948 - val_loss: 0.8094 - val_accuracy: 0.8647\n",
            "Epoch 280/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0149 - accuracy: 0.9951 - val_loss: 0.7536 - val_accuracy: 0.8740\n",
            "Epoch 281/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 0.7785 - val_accuracy: 0.8707\n",
            "Epoch 282/300\n",
            "54000/54000 [==============================] - 37s 689us/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.7209 - val_accuracy: 0.8733\n",
            "Epoch 283/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0092 - accuracy: 0.9970 - val_loss: 0.8306 - val_accuracy: 0.8658\n",
            "Epoch 284/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.7461 - val_accuracy: 0.8747\n",
            "Epoch 285/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.7601 - val_accuracy: 0.8698\n",
            "Epoch 286/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0132 - accuracy: 0.9964 - val_loss: 0.6914 - val_accuracy: 0.8698\n",
            "Epoch 287/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.8407 - val_accuracy: 0.8585\n",
            "Epoch 288/300\n",
            "54000/54000 [==============================] - 37s 689us/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.7727 - val_accuracy: 0.8723\n",
            "Epoch 289/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.7443 - val_accuracy: 0.8687\n",
            "Epoch 290/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.7312 - val_accuracy: 0.8773\n",
            "Epoch 291/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.7619 - val_accuracy: 0.8785\n",
            "Epoch 292/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 0.7978 - val_accuracy: 0.8737\n",
            "Epoch 293/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.7871 - val_accuracy: 0.8673\n",
            "Epoch 294/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0110 - accuracy: 0.9967 - val_loss: 0.7213 - val_accuracy: 0.8757\n",
            "Epoch 295/300\n",
            "54000/54000 [==============================] - 37s 686us/step - loss: 0.0106 - accuracy: 0.9966 - val_loss: 0.8673 - val_accuracy: 0.8577\n",
            "Epoch 296/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0126 - accuracy: 0.9963 - val_loss: 0.8076 - val_accuracy: 0.8732\n",
            "Epoch 297/300\n",
            "54000/54000 [==============================] - 37s 685us/step - loss: 0.0110 - accuracy: 0.9966 - val_loss: 0.7864 - val_accuracy: 0.8762\n",
            "Epoch 298/300\n",
            "54000/54000 [==============================] - 37s 688us/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.7234 - val_accuracy: 0.8792\n",
            "Epoch 299/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0075 - accuracy: 0.9975 - val_loss: 0.7694 - val_accuracy: 0.8788\n",
            "Epoch 300/300\n",
            "54000/54000 [==============================] - 37s 687us/step - loss: 0.0112 - accuracy: 0.9968 - val_loss: 0.7740 - val_accuracy: 0.8652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f7ba5ba26a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dp_QuZfq7qwa",
        "colab_type": "code",
        "outputId": "56b68e6e-c25e-4b42-eb7e-76515f921a5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.7739506034056346\n",
            "Test accuracy: 0.8651666641235352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Cz1-7BIhqm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBDlFmtJqGx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"model_weights.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3ZKlPg8qWDN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = pd.read_csv(\"testX.csv\")\n",
        "pred = pred.drop(columns=['Id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdzhAm6OqoaA",
        "colab_type": "code",
        "outputId": "50d63cf6-dd57-4948-839b-a1eb3015bcf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_pred = pred.values.reshape((-1, 28, 28, 1))\n",
        "x_pred.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8SSwbHwq8lu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_pred = x_pred.astype(\"float32\")/255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGAqYW4-q_zu",
        "colab_type": "code",
        "outputId": "8c559eb3-1a6f-448d-eb2f-36ea120a13a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "start1 = time.time()\n",
        "y_pred = model.predict(x_pred)\n",
        "end1 = time.time()\n",
        "\n",
        "print(end1 - start1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9.760201215744019\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ldWkj_rRnv",
        "colab_type": "code",
        "outputId": "a9608379-2748-4871-e1c2-397104ab462c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_ans = list()\n",
        "\n",
        "for i in range(0, 10000):\n",
        "  k = 0\n",
        "  for j in range(1, 5):\n",
        "    if(y_pred[i][j] > y_pred[i][k]):\n",
        "      k = j\n",
        "  y_ans.append(k)\n",
        "\n",
        "len(y_ans)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cy0UqbAOtWl9",
        "colab_type": "code",
        "outputId": "d044782b-5940-4e60-9590-659bdfb45a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "pppp = pd.read_csv(\"testX.csv\")\n",
        "id = pppp['Id']\n",
        "len(id)\n",
        "ans = np.column_stack((id, y_ans))\n",
        "print(ans.shape)\n",
        "df_ans = pd.DataFrame(data=ans, columns=['Id', 'Label'])\n",
        "df_ans.describe()\n",
        "df_ans.to_csv(\"samplesubmission.csv\", index = False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}